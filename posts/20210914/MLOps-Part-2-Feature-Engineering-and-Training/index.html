<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Previously, we have set up the main skeleton of our training pipeline using mlflow project and implemented a download step component. Now let’s continue building the training pipeline.  Right now we a">
<meta property="og:type" content="article">
<meta property="og:title" content="MLOps Part 2 - Feature Engineering and Training">
<meta property="og:url" content="https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/">
<meta property="og:site_name" content="Izzuddin Ahsanujunda Blog">
<meta property="og:description" content="Previously, we have set up the main skeleton of our training pipeline using mlflow project and implemented a download step component. Now let’s continue building the training pipeline.  Right now we a">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://drive.google.com/uc?export=view&id=1KVqCU7TUzuln1CPufvR60X9_a4Evqf1r">
<meta property="article:published_time" content="2021-09-14T16:00:18.000Z">
<meta property="article:modified_time" content="2022-08-05T15:46:45.037Z">
<meta property="article:author" content="Izzuddin Ahsanujunda">
<meta property="article:tag" content="data science, data analysis, machine learning, software development, data engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://drive.google.com/uc?export=view&id=1KVqCU7TUzuln1CPufvR60X9_a4Evqf1r">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/android-chrome-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>MLOps Part 2 - Feature Engineering and Training</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 6.2.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/iahsanujunda">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/posts/20220730/Does-FromSoft-explicitly-program-Malenia-to-skip-waterfowl-dance/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/posts/20210802/MLOps-Part-1-Intro-to-MLflow-Project-and-setting-up-our-first-step/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&text=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&is_video=false&description=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=MLOps Part 2 - Feature Engineering and Training&body=Check out this article: https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&name=MLOps Part 2 - Feature Engineering and Training&description=&lt;p&gt;Previously, we have set up the main skeleton of our training pipeline using mlflow project and implemented a &lt;code&gt;download&lt;/code&gt; step component. Now let’s continue building the training pipeline.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://drive.google.com/uc?export=view&amp;id=1KVqCU7TUzuln1CPufvR60X9_a4Evqf1r&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Right now we are going to develop the feature engineering and training part. For the sake of simplicity, we are going to implement a bare minimum feature engineering for our model, because we are looking to focus our work on mlops. It is very possible to develop a more rigorous feature engineering step that results in much better model performance.&lt;/p&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&t=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Develop-split-step"><span class="toc-number">1.</span> <span class="toc-text">Develop split step</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Develop-train-model-step"><span class="toc-number">2.</span> <span class="toc-text">Develop train_model step</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        MLOps Part 2 - Feature Engineering and Training
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Izzuddin Ahsanujunda</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-09-14T16:00:18.000Z" itemprop="datePublished">2021-09-14</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>Previously, we have set up the main skeleton of our training pipeline using mlflow project and implemented a <code>download</code> step component. Now let’s continue building the training pipeline.</p>
<p><img src="https://drive.google.com/uc?export=view&id=1KVqCU7TUzuln1CPufvR60X9_a4Evqf1r" alt="image"></p>
<p>Right now we are going to develop the feature engineering and training part. For the sake of simplicity, we are going to implement a bare minimum feature engineering for our model, because we are looking to focus our work on mlops. It is very possible to develop a more rigorous feature engineering step that results in much better model performance.</p>
<span id="more"></span>
<h3 id="Develop-split-step"><a href="#Develop-split-step" class="headerlink" title="Develop split step"></a>Develop split step</h3><p>Let’s start with creating a new file that will split our downloaded data on wandb into a training part and testing part.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch nyc_airbnb/split_train_test.py</span><br></pre></td></tr></table></figure>
<p>Just like <code>nyc_airbnb/get_data.py</code>, here we will build the logic to split our full dataset into a training and testing set. We do this early to safeguard our model from information leakage. Open the new file and put the following code into it.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"># ./nyc_airbnb/split_train_test.py</span><br><span class="line">import argparse</span><br><span class="line">import logging</span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line">import tempfile</span><br><span class="line"> </span><br><span class="line">import wandb</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"> </span><br><span class="line">sys.path.append(&quot;..&quot;)</span><br><span class="line">from nyc_aurbnb.utils.base_runner import BaseRunner</span><br><span class="line"> </span><br><span class="line">logging.basicConfig(</span><br><span class="line">   level=logging.INFO,</span><br><span class="line">   format=&quot;%(asctime)-15s %(levelname)s - %(message)s&quot;)</span><br><span class="line">logger = logging.getLogger()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class SplitRunner(BaseRunner):</span><br><span class="line">   def __init__(self,</span><br><span class="line">                wandb_run,</span><br><span class="line">                test_size,</span><br><span class="line">                random_seed,</span><br><span class="line">                stratify_by):</span><br><span class="line">       super().__init__(wandb_run)</span><br><span class="line">       self.test_size = test_size</span><br><span class="line">       self.random_seed = random_seed</span><br><span class="line">       self.stratify_by = stratify_by</span><br><span class="line"> </span><br><span class="line">   def split_train_test(self,</span><br><span class="line">                        data: pd.DataFrame,</span><br><span class="line">                        dir_name: str):</span><br><span class="line">       trainval, test = train_test_split(</span><br><span class="line">           data,</span><br><span class="line">           test_size=float(self.test_size),</span><br><span class="line">           random_state=int(self.random_seed),</span><br><span class="line">           stratify=data[self.stratify_by] if self.stratify_by != &#x27;none&#x27; else None,</span><br><span class="line">       )</span><br><span class="line"> </span><br><span class="line">       logger.info(f&#x27;train proportion contains &#123;trainval.shape[0]&#125;&#x27;)</span><br><span class="line">       logger.info(f&#x27;test proportion contains &#123;test.shape[0]&#125;&#x27;)</span><br><span class="line"> </span><br><span class="line">       file_dict = &#123;&#125;</span><br><span class="line">       for data_frame, name in zip([trainval, test], [&#x27;trainval&#x27;, &#x27;test&#x27;]):</span><br><span class="line">           logger.info(f&quot;Uploading &#123;name&#125;_data.parquet dataset&quot;)</span><br><span class="line">           temp_file = os.path.join(dir_name, f&#x27;&#123;name&#125;_data.parquet&#x27;)</span><br><span class="line">           data_frame.to_parquet(</span><br><span class="line">               temp_file,</span><br><span class="line">               index=False,</span><br><span class="line">               engine=&#x27;pyarrow&#x27;,</span><br><span class="line">               compression=&#x27;gzip&#x27;)</span><br><span class="line">           file_dict[f&#x27;&#123;name&#125;_data&#x27;] = temp_file</span><br><span class="line"> </span><br><span class="line">       return file_dict</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">   parser = argparse.ArgumentParser(description=&quot;Split training dataset&quot;)</span><br><span class="line">   parser.add_argument(&quot;input_artifact&quot;,</span><br><span class="line">                       type=str,</span><br><span class="line">                       help=&quot;Reference to mlflow artifact of input data&quot;)</span><br><span class="line">   parser.add_argument(&quot;test_size&quot;,</span><br><span class="line">                       type=str,</span><br><span class="line">                       help=&quot;The size of test data&quot;)</span><br><span class="line">   parser.add_argument(&quot;random_seed&quot;,</span><br><span class="line">                       type=str,</span><br><span class="line">                       help=&quot;Random seed&quot;)</span><br><span class="line">   parser.add_argument(&quot;stratify_by&quot;,</span><br><span class="line">                       type=str,</span><br><span class="line">                       help=&quot;Column to use for stratification&quot;)</span><br><span class="line">   args = parser.parse_args()</span><br><span class="line"> </span><br><span class="line">   runner = SplitRunner(</span><br><span class="line">       wandb.init(job_type=&quot;split_data&quot;),</span><br><span class="line">       args.test_size,</span><br><span class="line">       args.random_seed,</span><br><span class="line">       args.stratify_by</span><br><span class="line">   )</span><br><span class="line">   dataset = runner.retrieve_dataset_artifact(args.input_artifact)</span><br><span class="line"> </span><br><span class="line">   with tempfile.TemporaryDirectory() as temp_dir:</span><br><span class="line">       files = runner.split_train_test(dataset, temp_dir)</span><br><span class="line">       for key, file_name in files.items():</span><br><span class="line">           _ = runner.log_artifact(</span><br><span class="line">               f&#x27;&#123;key&#125;.parquet&#x27;,</span><br><span class="line">               key,</span><br><span class="line">               f&#x27;&#123;key&#125; split of the dataset&#x27;,</span><br><span class="line">               file_name</span><br><span class="line">           )</span><br><span class="line"> </span><br><span class="line">   sys.exit(0)</span><br></pre></td></tr></table></figure>
<p>The logic here is quite simple, we listen for arguments of which artifact name from wandb we need to process. The actual artifact name will be supplied by the main entry point. We then download it, split it using sklearn’s <code>train_test_split</code>, and the result test and train split is logged back to wandb. The name of the artifact for both training portion and testing portion is also configurable, so that main entry point can further pass it on to the next component.</p>
<p>Now we have to strap this into <code>MLproject</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#./MLproject</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">entry_points:</span><br><span class="line"> main:</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"> get_data:</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"> split:</span><br><span class="line">   parameters:</span><br><span class="line">     input_artifact:</span><br><span class="line">       description: Artifact to split (a CSV file)</span><br><span class="line">       type: string</span><br><span class="line">     test_size:</span><br><span class="line">       description: Size of the test split. Fraction of the dataset, or number of items</span><br><span class="line">       type: string</span><br><span class="line">     random_seed:</span><br><span class="line">       description: Seed for the random number generator. Use this for reproducibility</span><br><span class="line">       type: string</span><br><span class="line">       default: 42</span><br><span class="line">     stratify_by:</span><br><span class="line">       description: Column to use for stratification (if any)</span><br><span class="line">       type: string</span><br><span class="line">       default: &#x27;none&#x27;</span><br><span class="line">   command: &quot;python nyc_airbnb/split_train_test.py</span><br><span class="line">       &#123;input_artifact&#125;</span><br><span class="line">       &#123;test_size&#125;</span><br><span class="line">       &#123;random_seed&#125;</span><br><span class="line">       &#123;stratify_by&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>With <code>MLproject</code> entry point set, we can now call this from <code>main.py</code> with values retrieved from <code>config.yaml</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># ./main.py</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">_steps = [</span><br><span class="line">  &quot;download&quot;,</span><br><span class="line">  &quot;split&quot;</span><br><span class="line">]</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">      if &quot;download&quot; in active_steps:</span><br><span class="line">        ...</span><br><span class="line">        ...</span><br><span class="line">      if &quot;split&quot; in active_steps:</span><br><span class="line">           _ = mlflow.run(</span><br><span class="line">               os.path.join(hydra.utils.get_original_cwd()),</span><br><span class="line">               &quot;split&quot;,</span><br><span class="line">               parameters=&#123;</span><br><span class="line">                   &quot;input_artifact&quot;: &quot;raw_data.parquet:latest&quot;,</span><br><span class="line">                   &quot;test_size&quot;: config[&#x27;modeling&#x27;][&#x27;test_size&#x27;],</span><br><span class="line">                   &quot;random_seed&quot;: config[&#x27;modeling&#x27;][&#x27;random_seed&#x27;],</span><br><span class="line">                   &quot;stratify_by&quot;: config[&#x27;modeling&#x27;][&#x27;stratify_by&#x27;],</span><br><span class="line">               &#125;</span><br><span class="line">           )</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">./config.yaml</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">modeling:</span><br><span class="line"> # Fraction of data to use for test (the remaining will be used for train and validation)</span><br><span class="line"> test_size: 0.2</span><br><span class="line"> # Fraction of remaining data to use for validation</span><br><span class="line"> val_size: 0.2</span><br><span class="line"> # Fix this for reproducibility, change to have new splits</span><br><span class="line"> random_seed: 42</span><br><span class="line"> # Column to use for stratification (use &quot;none&quot; for no stratification)</span><br><span class="line"> stratify_by: &quot;none&quot;</span><br></pre></td></tr></table></figure>
<p>With this we have set up the split step and we can test run this. We can either run entire pipeline, or just the <code>split</code> part. This is made possible because we pass <code>raw_data.parquet:latest</code> as an argument to <code>split</code> entry point. The <code>:latest</code> tag means we will always retrieve the most recent version of the file. If we have multiple version of our wadnb artifact, we can also pass the specific version as tag, such as <code>v0</code> for the first ever logged version of that particular artifact, or <code>v1</code> for the second version, etc.</p>
<p>To run only this component step, use <code>mlflow run myc_airbnb -P steps=split</code>. To run the entire pipeline, the command is <code>mlflow run myc_airbnb</code>.</p>
<p>After the run is finished, check our wandb dashboard and see if a new artifact called <code>trainval_data</code> and <code>test_data</code> exists. Both of these will be passed to subsequent steps.</p>
<h3 id="Develop-train-model-step"><a href="#Develop-train-model-step" class="headerlink" title="Develop train_model step"></a>Develop train_model step</h3><p>Let’s put in the logic for training our model. Create a new file for this.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch nyc_airbnb/train.py</span><br></pre></td></tr></table></figure>
<p>And paste in the following code.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"># ./nyc_airbnb/train.py</span><br><span class="line"> </span><br><span class="line">import argparse</span><br><span class="line">import json</span><br><span class="line">import logging</span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">import sys</span><br><span class="line">from typing import Dict</span><br><span class="line"> </span><br><span class="line">import mlflow</span><br><span class="line">import pandas as pd</span><br><span class="line">import wandb</span><br><span class="line">from sklearn.metrics import r2_score, mean_absolute_error</span><br><span class="line"> </span><br><span class="line">sys.path.append(&quot;..&quot;)</span><br><span class="line">from nyc_airbnb.utils.base_runner import BaseRunner</span><br><span class="line">from nyc_airbnb.utils.pipeline import get_inference_pipeline</span><br><span class="line"> </span><br><span class="line">logging.basicConfig(</span><br><span class="line">   level=logging.INFO,</span><br><span class="line">   format=&quot;%(asctime)-15s %(levelname)s - %(message)s&quot;)</span><br><span class="line">logger = logging.getLogger()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class TrainModelRunner(BaseRunner):</span><br><span class="line">   def __init__(self,</span><br><span class="line">                wandb_run,</span><br><span class="line">                label,</span><br><span class="line">                random_seed,</span><br><span class="line">                stratify_by</span><br><span class="line">                val_size):</span><br><span class="line">       super().__init__(wandb_run)</span><br><span class="line">       self.label = label</span><br><span class="line">       self.val_size = val_size</span><br><span class="line">       self.stratify_by = stratify_by</span><br><span class="line">       self.random_seed = random_seed</span><br><span class="line"> </span><br><span class="line">   def train(self,</span><br><span class="line">             data: pd.DataFrame,</span><br><span class="line">             rf_config: Dict[str, float],</span><br><span class="line">             max_tfidf_features):</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       Train a model by running fit() method of pipeline.</span><br><span class="line">       Args:</span><br><span class="line">           data: A DataFrame of training dataset</span><br><span class="line">           rf_config:</span><br><span class="line">               A configuration dict to be used as model parameters</span><br><span class="line">       &quot;&quot;&quot;</span><br><span class="line">       y = data[self.label]</span><br><span class="line">       X = data.drop(self.label, axis=1)</span><br><span class="line">      </span><br><span class="line">       X_train, X_val, y_train, y_val = train_test_split(</span><br><span class="line">         X,</span><br><span class="line">         y,</span><br><span class="line">         test_size=self.val_size,</span><br><span class="line">         stratify=X[self.stratify_by],</span><br><span class="line">         random_state=self.random_seed</span><br><span class="line">       )</span><br><span class="line"> </span><br><span class="line">       logger.info(&quot;Preparing pipeline&quot;)</span><br><span class="line">       lasso_pipe = get_inference_pipeline(</span><br><span class="line">         rf_config,</span><br><span class="line">         max_tfidf_features</span><br><span class="line">       )</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">       logger.info(&quot;Training model&quot;)</span><br><span class="line">       trained_model = lasso_pipe.fit(X_train, y_train)</span><br><span class="line"> </span><br><span class="line">       # training performance metric</span><br><span class="line">       y_pred = lasso_pipe.predict(X)</span><br><span class="line">       r2 = r2_score(y, y_pred)</span><br><span class="line">       mae = mean_absolute_error(y, y_pred)</span><br><span class="line"> </span><br><span class="line">       return r2, mae, trained_model</span><br><span class="line"> </span><br><span class="line">   def persist_model(self, model, model_artifact_name: str):</span><br><span class="line">       persist_dir = f&#x27;&#123;model_artifact_name&#125;_dir&#x27;</span><br><span class="line"> </span><br><span class="line">       # Remove if exists</span><br><span class="line">       if os.path.exists(persist_dir):</span><br><span class="line">           shutil.rmtree(persist_dir)</span><br><span class="line"> </span><br><span class="line">       mlflow.sklearn.save_model(</span><br><span class="line">           model,</span><br><span class="line">           persist_dir,</span><br><span class="line">       )</span><br><span class="line"> </span><br><span class="line">       self.log_model(</span><br><span class="line">           model_artifact_name,</span><br><span class="line">           &quot;model_export&quot;,</span><br><span class="line">           &quot;Pytorch lasso model export&quot;,</span><br><span class="line">           persist_dir)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">   # Process arguments</span><br><span class="line">   parser = argparse.ArgumentParser(description=&quot;Train the model&quot;)</span><br><span class="line"> </span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;trainval_artifact&quot;,</span><br><span class="line">       type=str,</span><br><span class="line">       help=&quot;Artifact containing the training dataset. It will be split into train and validation&quot;</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;val_size&quot;,</span><br><span class="line">       type=float,</span><br><span class="line">       help=&quot;Size of the validation split. Fraction of the dataset, or number of items&quot;,</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;random_seed&quot;,</span><br><span class="line">       type=int,</span><br><span class="line">       help=&quot;Seed for random number generator&quot;,</span><br><span class="line">       default=42,</span><br><span class="line">       required=False,</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;stratify_by&quot;,</span><br><span class="line">       type=str,</span><br><span class="line">       help=&quot;Column to use for stratification&quot;,</span><br><span class="line">       default=&quot;none&quot;,</span><br><span class="line">       required=False,</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;rf_config&quot;,</span><br><span class="line">       help=&quot;Random forest configuration. A JSON dict that will be passed to the &quot;</span><br><span class="line">       &quot;scikit-learn constructor for RandomForestRegressor.&quot;,</span><br><span class="line">       default=&quot;&#123;&#125;&quot;,</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;max_tfidf_features&quot;,</span><br><span class="line">       help=&quot;Maximum number of words to consider for the TFIDF&quot;,</span><br><span class="line">       default=10,</span><br><span class="line">       type=int</span><br><span class="line">   )</span><br><span class="line">   parser.add_argument(</span><br><span class="line">       &quot;output_artifact&quot;,</span><br><span class="line">       type=str,</span><br><span class="line">       help=&quot;Name for the output serialized model&quot;,</span><br><span class="line">       required=True,</span><br><span class="line">   )</span><br><span class="line"> </span><br><span class="line">   wandb_run = wandb.init(job_type=&quot;training_model&quot;)</span><br><span class="line"> </span><br><span class="line">   with open(args.rf_config) as fp:</span><br><span class="line">       rf_config = json.load(fp)</span><br><span class="line"> </span><br><span class="line">   # Log model config to wandb runs</span><br><span class="line">   wandb_run.config.update(rf_config)</span><br><span class="line"> </span><br><span class="line">   # Run training</span><br><span class="line">   runner = TrainModelRunner(</span><br><span class="line">       wandb_run,</span><br><span class="line">       label=args.label</span><br><span class="line">   )</span><br><span class="line">   training_set = runner.retrieve_dataset_artifact(args.train_artifact)</span><br><span class="line">   r2, mae, TRAINED_MODEL = runner.train(training_set, rf_config, args.max_tfidf_features)</span><br><span class="line"> </span><br><span class="line">   # Logging to wandb</span><br><span class="line">   logger.info(f&#x27;R2 score is &#123;r2&#125;&#x27;)</span><br><span class="line">   logger.info(f&#x27;MAE loss is &#123;mae&#125;&#x27;)</span><br><span class="line">   wandb_run.summary[&#x27;r2&#x27;] = r2</span><br><span class="line">   wandb_run.log(&#123;</span><br><span class="line">       &quot;mae&quot;: mae,</span><br><span class="line">       &quot;r2&quot;: r2</span><br><span class="line">   &#125;)</span><br><span class="line"> </span><br><span class="line">   # Persist model</span><br><span class="line">   logger.info(&#x27;Exporting model&#x27;)</span><br><span class="line">   runner.persist_model(TRAINED_MODEL, args.output_artifact)</span><br><span class="line"> </span><br><span class="line">   sys.exit(0)</span><br></pre></td></tr></table></figure>
<p>In this step, we are going to train our model on the training split of the data. We score the performance on the model on <em>training</em> data, and log the trained model artifact and the performance into wandb. Later on, we are going use the same trained model artfact to score to <em>testing</em> data. Doing this gave us several advantage:</p>
<ol>
<li>It safeguards us from data leakage. Remember that we split our dataset immediately after retrieving them from source, any cleaning&#x2F;preprocessing we do in this step will only be applied to training split of the data.</li>
<li>Scoring separately allows us to safeguard from overfitting. We might apply cross-validation in our training step to discover the most optimal combination of hyperparameters and preprocessing logic, and the same hyperparameter and preprocessing will be applied upon testing data that we haven’t seen at all during training. This will allow us to prepare our model to deal with new data in production.</li>
</ol>
<p>We are also going to organise the source code in a way that is easy to maintain and extend. Here we are only going to retrieve training data and slap it into the training pipeline. The actual training and preprocessing logic will be built on different modules. This way, we may plug-in and plug-out any preprocessing logic or even swap out the model from logistic regression into gradient boosting, the training function here won’t care as long as it can get the pipeline object.</p>
<p>To achieve this, we need to create the <code>get_inference_pipeline</code> function; it will return a scikit-learn compatible <code>Pipeline</code> object. <code>Pipeline</code> can assemble multiple estimators and transformers together. If we need to apply <code>OneHotEncoding</code>, <code>StandardScaler</code> and <code>RandomForest</code> together, we put them into a <code>Pipeline</code> and we can all <code>fit</code> only once from the <code>Pipeline</code>. The <code>Pipeline</code> will be the ones handling <code>fit</code> execution in sequence. When we want to save these fitted estimators together, we just need to save the <code>Pipeline</code>.</p>
<p>Create the module to store our <code>Pipeline</code> logic.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch nyc_airbnb/utils/pipeline.py</span><br></pre></td></tr></table></figure>
<p>Write the following code into the new file.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"># ./nyc_airbnb/utils/pipeline.py</span><br><span class="line">def get_inference_pipeline(rf_config, max_tfidf_features):</span><br><span class="line">   # Let&#x27;s handle the categorical features first</span><br><span class="line">   # Ordinal categorical are categorical values for which the order is meaningful, for example</span><br><span class="line">   # for room type: &#x27;Entire home/apt&#x27; &gt; &#x27;Private room&#x27; &gt; &#x27;Shared room&#x27;</span><br><span class="line">   ordinal_categorical = [&quot;room_type&quot;]</span><br><span class="line">   non_ordinal_categorical = [&quot;neighbourhood_group&quot;]</span><br><span class="line">   # NOTE: we do not need to impute room_type because the type of the room</span><br><span class="line">   # is mandatory on the websites, so missing values are not possible in production</span><br><span class="line">   # (nor during training). That is not true for neighbourhood_group</span><br><span class="line">   ordinal_categorical_preproc = OrdinalEncoder()</span><br><span class="line"> </span><br><span class="line">   ######################################</span><br><span class="line">   # Build a pipeline with two steps:</span><br><span class="line">   # 1 - A SimpleImputer(strategy=&quot;most_frequent&quot;) to impute missing values</span><br><span class="line">   # 2 - A OneHotEncoder() step to encode the variable</span><br><span class="line">   non_ordinal_categorical_preproc = make_pipeline(</span><br><span class="line">       SimpleImputer(strategy=&quot;most_frequent&quot;),</span><br><span class="line">       OneHotEncoder()</span><br><span class="line">   )</span><br><span class="line">   ######################################</span><br><span class="line"> </span><br><span class="line">   # Let&#x27;s impute the numerical columns to make sure we can handle missing values</span><br><span class="line">   # (note that we do not scale because the RF algorithm does not need that)</span><br><span class="line">   zero_imputed = [</span><br><span class="line">       &quot;minimum_nights&quot;,</span><br><span class="line">       &quot;number_of_reviews&quot;,</span><br><span class="line">       &quot;reviews_per_month&quot;,</span><br><span class="line">       &quot;calculated_host_listings_count&quot;,</span><br><span class="line">       &quot;availability_365&quot;,</span><br><span class="line">       &quot;longitude&quot;,</span><br><span class="line">       &quot;latitude&quot;</span><br><span class="line">   ]</span><br><span class="line">   zero_imputer = SimpleImputer(strategy=&quot;constant&quot;, fill_value=0)</span><br><span class="line"> </span><br><span class="line">   # A MINIMAL FEATURE ENGINEERING step:</span><br><span class="line">   # we create a feature that represents the number of days passed since the last review</span><br><span class="line">   # First we impute the missing review date with an old date (because there hasn&#x27;t been</span><br><span class="line">   # a review for a long time), and then we create a new feature from it,</span><br><span class="line">   date_imputer = make_pipeline(</span><br><span class="line">       SimpleImputer(strategy=&#x27;constant&#x27;, fill_value=&#x27;2010-01-01&#x27;),</span><br><span class="line">       FunctionTransformer(delta_date_feature, check_inverse=False, validate=False)</span><br><span class="line">   )</span><br><span class="line"> </span><br><span class="line">   # Some minimal NLP for the &quot;name&quot; column</span><br><span class="line">   reshape_to_1d = FunctionTransformer(np.reshape, kw_args=&#123;&quot;newshape&quot;: -1&#125;)</span><br><span class="line">   name_tfidf = make_pipeline(</span><br><span class="line">       SimpleImputer(strategy=&quot;constant&quot;, fill_value=&quot;&quot;),</span><br><span class="line">       reshape_to_1d,</span><br><span class="line">       TfidfVectorizer(</span><br><span class="line">           binary=False,</span><br><span class="line">           max_features=max_tfidf_features,</span><br><span class="line">           stop_words=&#x27;english&#x27;</span><br><span class="line">       ),</span><br><span class="line">   )</span><br><span class="line"> </span><br><span class="line">   # Let&#x27;s put everything together</span><br><span class="line">   preprocessor = ColumnTransformer(</span><br><span class="line">       transformers=[</span><br><span class="line">           (&quot;ordinal_cat&quot;, ordinal_categorical_preproc, ordinal_categorical),</span><br><span class="line">           (&quot;non_ordinal_cat&quot;, non_ordinal_categorical_preproc, non_ordinal_categorical),</span><br><span class="line">           (&quot;impute_zero&quot;, zero_imputer, zero_imputed),</span><br><span class="line">           (&quot;transform_date&quot;, date_imputer, [&quot;last_review&quot;]),</span><br><span class="line">           (&quot;transform_name&quot;, name_tfidf, [&quot;name&quot;])</span><br><span class="line">       ],</span><br><span class="line">       remainder=&quot;drop&quot;,  # This drops the columns that we do not transform</span><br><span class="line">   )</span><br><span class="line"> </span><br><span class="line">   processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + [&quot;last_review&quot;, &quot;name&quot;]</span><br><span class="line"> </span><br><span class="line">   # Create random forest</span><br><span class="line">   random_Forest = RandomForestRegressor(**rf_config)</span><br><span class="line"> </span><br><span class="line">   ######################################</span><br><span class="line">   # Create the inference pipeline. The pipeline must have 2 steps: a step called &quot;preprocessor&quot; applying the</span><br><span class="line">   # ColumnTransformer instance that we saved in the `preprocessor` variable, and a step called &quot;random_forest&quot;</span><br><span class="line">   # with the random forest instance that we just saved in the `random_forest` variable.</span><br><span class="line">   # HINT: Use the explicit Pipeline constructor so you can assign the names to the steps, do not use make_pipeline</span><br><span class="line">   sk_pipe = Pipeline(</span><br><span class="line">       steps=[</span><br><span class="line">           (&quot;preprocessor&quot;, preprocessor),</span><br><span class="line">           (&quot;random_forest&quot;, random_Forest)</span><br><span class="line">       ]</span><br><span class="line">   )</span><br><span class="line"> </span><br><span class="line">   return sk_pipe, processed_features</span><br></pre></td></tr></table></figure>
<p>Here we declare all preprocessing logic for each data type, ordinal categorical, nominal categorical, numeric, temporal, and textual. We strap all of these with <code>ColumnTransformer</code>, and the resulting transformer can be put into a <code>Pipeline</code> step. The final pipeline just needs to combine the <code>preprocessor</code> step and <code>random_forest</code> model.</p>
<p>As we can see, we build the steps in a declarative way, so we can change any part of the steps and it can be called by our <code>train</code> entry point as long as we return <code>Pipeline</code> from here.</p>
<p>Now that we have created the entry point for training, we just have to call it from our main entry point. Let’s start by making the entry point for training in our MLproject.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">#./MLproject</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">entry_points:</span><br><span class="line"> main:</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"> get_data:</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"> split:</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"> train:</span><br><span class="line">   parameters:</span><br><span class="line">     trainval_artifact:</span><br><span class="line">       description: Train dataset</span><br><span class="line">       type: string</span><br><span class="line">     val_size:</span><br><span class="line">       description: Size of the validation split. Fraction of the dataset, or number of items</span><br><span class="line">       type: string</span><br><span class="line">     random_seed:</span><br><span class="line">       description: Seed for the random number generator. Use this for reproducibility</span><br><span class="line">       type: string</span><br><span class="line">       default: 42</span><br><span class="line">     stratify_by:</span><br><span class="line">       description: Column to use for stratification (if any)</span><br><span class="line">       type: string</span><br><span class="line">       default: &#x27;none&#x27;</span><br><span class="line">     rf_config:</span><br><span class="line">       description: Random forest configuration. A path to a JSON file with the configuration that will</span><br><span class="line">                    be passed to the scikit-learn constructor for RandomForestRegressor.</span><br><span class="line">       type: string</span><br><span class="line">     max_tfidf_features:</span><br><span class="line">       description: Maximum number of words to consider for the TFIDF</span><br><span class="line">       type: string</span><br><span class="line">     output_artifact:</span><br><span class="line">       description: Name for the output artifact</span><br><span class="line">       type: string</span><br><span class="line">   command: &quot;python nyc_airbnb/train.py</span><br><span class="line">               &#123;trainval_artifact&#125;</span><br><span class="line">               &#123;val_size&#125;</span><br><span class="line">               &#123;random_seed&#125;</span><br><span class="line">               &#123;stratify_by&#125;</span><br><span class="line">               &#123;rf_config&#125;</span><br><span class="line">               &#123;max_tfidf_features&#125;</span><br><span class="line">               &#123;output_artifact&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>Now we can call this from <code>main.py</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># ./main.py</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">_steps = [</span><br><span class="line">  &quot;download&quot;,</span><br><span class="line">  &quot;split&quot;,</span><br><span class="line">  &quot;train&quot;</span><br><span class="line">]</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">     if &quot;download&quot; in active_steps:</span><br><span class="line">        ...</span><br><span class="line">        ...</span><br><span class="line">     if &quot;split&quot; in active_steps:</span><br><span class="line">        ...</span><br><span class="line">        ...</span><br><span class="line">     if &quot;train&quot; in active_steps:</span><br><span class="line">           # NOTE: we need to serialize the random forest configuration into JSON</span><br><span class="line">           rf_config = os.path.abspath(&quot;rf_config.json&quot;)</span><br><span class="line">           with open(rf_config, &quot;w+&quot;) as fp:</span><br><span class="line">               json.dump(dict(config[&quot;modeling&quot;][&quot;random_forest&quot;].items()), fp)  # DO NOT TOUCH</span><br><span class="line">           # NOTE: use the rf_config we just created as the rf_config parameter for the train_random_forest</span><br><span class="line">           _ = mlflow.run(</span><br><span class="line">             os.path.join(hydra.utils.get_original_cwd()),</span><br><span class="line">             &quot;train&quot;,</span><br><span class="line">             parameters=&#123;</span><br><span class="line">                 &quot;trainval_artifact&quot;: &quot;trainval_data.csv:latest&quot;,</span><br><span class="line">                 &quot;val_size&quot;: config[&quot;modeling&quot;][&quot;val_size&quot;],</span><br><span class="line">                 &quot;random_seed&quot;: config[&quot;modeling&quot;][&quot;random_seed&quot;],</span><br><span class="line">                 &quot;stratify_by&quot;: config[&quot;modeling&quot;][&quot;stratify_by&quot;],</span><br><span class="line">                 &quot;rf_config&quot;: rf_config,</span><br><span class="line">                 &quot;max_tfidf_features&quot;: config[&quot;modeling&quot;][&quot;max_tfidf_features&quot;],</span><br><span class="line">                 &quot;output_artifact&quot;: &quot;random_forest_export&quot;,</span><br><span class="line">             &#125;,</span><br><span class="line">           )</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Before we finish the training part and test run this, we need to add the configuration in <code>config.yaml</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./config.yaml</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">modeling:</span><br><span class="line"> ...</span><br><span class="line"> ...</span><br><span class="line"> max_tfidf_features: 15</span><br><span class="line"> # NOTE: you can put here any parameter that is accepted by the constructor of</span><br><span class="line"> # RandomForestRegressor. This is a subsample, but more could be added:</span><br><span class="line"> random_forest:</span><br><span class="line">   n_estimators: 100</span><br><span class="line">   max_depth: 15</span><br><span class="line">   min_samples_split: 4</span><br><span class="line">   min_samples_leaf: 3</span><br><span class="line">   # Here -1 means all available cores</span><br><span class="line">   n_jobs: -1</span><br><span class="line">   criterion: mae</span><br><span class="line">   max_features: 0.5</span><br><span class="line">   # DO not change the following</span><br><span class="line">   oob_score: true</span><br></pre></td></tr></table></figure>
<p>Now we have everything ready to test run our training step. Same as previous example, we can run using mlflow cli.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlflow run nyc_airbnb/ -P steps=train</span><br></pre></td></tr></table></figure>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a target="_blank" rel="noopener" href="http://github.com/iahsanujunda">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Develop-split-step"><span class="toc-number">1.</span> <span class="toc-text">Develop split step</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Develop-train-model-step"><span class="toc-number">2.</span> <span class="toc-text">Develop train_model step</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&text=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&is_video=false&description=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=MLOps Part 2 - Feature Engineering and Training&body=Check out this article: https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&title=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&name=MLOps Part 2 - Feature Engineering and Training&description=&lt;p&gt;Previously, we have set up the main skeleton of our training pipeline using mlflow project and implemented a &lt;code&gt;download&lt;/code&gt; step component. Now let’s continue building the training pipeline.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://drive.google.com/uc?export=view&amp;id=1KVqCU7TUzuln1CPufvR60X9_a4Evqf1r&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Right now we are going to develop the feature engineering and training part. For the sake of simplicity, we are going to implement a bare minimum feature engineering for our model, because we are looking to focus our work on mlops. It is very possible to develop a more rigorous feature engineering step that results in much better model performance.&lt;/p&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://iahsanujunda.github.io/posts/20210914/MLOps-Part-2-Feature-Engineering-and-Training/&t=MLOps Part 2 - Feature Engineering and Training"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2022
    Izzuddin Ahsanujunda
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/iahsanujunda">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
